apiVersion: apps/v1
kind: Deployment
metadata:
  name: gemma
spec:
  replicas: 1
  selector:
    matchLabels:
      app: gemma
  template:
    metadata:
      labels:
        app: gemma
    spec:
      containers:
      - name: gemma
        image: mybvc365/drone_ai
        command: ["python3"]
        args: ["Chat2.py"]
        ports:
        - containerPort: 11434
        env:
        - name: OLLAMA_HOST
          value: "0.0.0.0"
        # If you want this to interact with Ollama on localhost,
        # make sure Ollama is running in the same pod or as a service

---
apiVersion: v1
kind: Service
metadata:
  name: emma-service
spec:
  selector:
    app: gemma
  ports:
    - protocol: TCP
      port: 11434
      targetPort: 11434
  type: ClusterIP
